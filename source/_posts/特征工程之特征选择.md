---
title: 特征工程之特征选择
tags: 机器学习
categories: 机器学习
mathjax: true
abbrlink: 27144
date: 2022-03-27 16:30:49
---

# 特征工程之特征选择

在选择特征时，一般特征有两种来源，一是已经整理好的各种特征，这类特征我们要去找适合我们问题的特征，另一类是从这些整理好的特征中去寻找高级特征。

## 1. 选择合适的特征

1. 寻找专家，向他咨询哪些特征会对预测结果产生影响，不论影响的大小都要选择。
2. 在降维之前，可以使用特征工程的方法去选择出比较重要的特征，例如，方差选择法。

​	选择特征一般有以下三种方法：

1. 过滤法：按照特征的发散性或者相关指标对各个特征进行评分，设定评分阈值，选择合适的特征，方差法就是过滤法的一种。
1. 包装法：根据目标函数，通常是预测效果评分，每次选择部分特征，或者排除部分特征。
3. 嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值的大小来选择特征。
   


### 1.1 过滤法选择特征

1. 方差选择法：计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征，使用 feature_selection 库中的 VarianceThreshold 类

   来选择特征。

2. 相关系数法：计算各个特征对目标值的相关系数以及相关系数的 P 值，主要用于输出连续值的监督学习算法中，使用 

   feature_selection 库中的 SelectKBest 结合相关系数来选择特征。

3. 卡方检验：可以检验某个特征分步和输出值之间的相关性，使用 feature_selection 库中的 SelectKBest 类结合卡方检验来选择特征。

4. 互信息：从信息熵的角度分析各个特征和输出值之间的评分关系，互信息越大，说明该特征和输出值之间的相关性越大，越需要保留，

   使用 feature_selection 库中的 SelectKBest 结合最大信息系数来选择特征。


### 1.2 包装法选择特征

1. 递归特征消除法

   递归特征消除法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。对特征含有权重的预测模型(例如，线性模型对应参数coefficients)，RFE通过**递归减少考察的特征集规模来选择特征**。首先，预测模型在原始特征上训练，每个特征指定一个权重。之后，那些拥有最小绝对值权重的特征被踢出特征集。如此往复递归，直至剩余的特征数量达到所需的特征数量。

   ```python
   from sklearn.feature_selection import RFE
   from sklearn.linear_model import LogisticRegression
   
   #递归特征消除法，返回特征选择后的数据
   #参数estimator为基模型
   #参数n_features_to_select为选择的特征个数
   RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)
   ```


### 1.3 嵌入法选择特征

嵌入法也是用机器学习的方法来选择特征，但是它和RFE的区别是它不是通过不停的筛掉特征来进行训练，而是使用的都是特征全集。在sklearn中，使用SelectFromModel函数来选择特征。

1. 基于惩罚项的特征选择法

​		最常用的是使用L1正则化和L2正则化来选择特征。当正则化系数大到一定程度时，部分特征系数会变成 0 ，当再增大，那么所有特征的系数都会趋于 0 ，但是我们会发现有些特征会先趋于 0 ，把这类特征筛选掉。基模型是逻辑回归模型。

```python
from sklearn.feature_selection import SelectFromModel
 
#带L1和L2惩罚项的逻辑回归作为基模型的特征选择
#参数threshold为权值系数之差的阈值
SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target)
```

2. 基于树模型的特征选择法

​		树模型中GBDT也可用来作为基模型进行特征选择，使用feature_selection库的SelectFromModel类结合GBDT模型。

```python
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import GradientBoostingClassifier

#GBDT作为基模型的特征选择
SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)
```



## 2 寻找高级特征

可以根据上面选择的初级特征来获得一些二级特征，例如已有 距离 和 时间 两个特征，可以得出 速度这个特征，还可以有三级、四级特征。

寻找高级特征的方法：

* 若干项特征加和： 我们假设你希望根据每日销售额得到一周销售额的特征。你可以将最近的7天的销售额相加得到。
* 若干项特征之差： 假设你已经拥有每周销售额以及每月销售额两项特征，可以求一周前一月内的销售额。
* 若干项特征乘积： 假设你有商品价格和商品销量的特征，那么就可以得到销售额的特征。
* 若干项特征除商： 假设你有每个用户的销售额和购买的商品件数，那么就是得到该用户平均每件商品的销售额。

当模型的效率得不到进一步提高时，可以考虑寻找高级特征。































