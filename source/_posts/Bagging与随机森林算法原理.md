---
title: Bagging与随机森林算法原理
tags: 机器学习
categories: 机器学习
mathjax: true
abbrlink: 39043
date: 2022-03-26 20:08:30
---

# Bagging与随机森林算法原理

随机采样：从训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。就是说，之前采集的样本仍有可能继续被采集到，

Bagging算法一般会随机采集和训练样本数一样的个数的样本。这样得到的采样集和训练集样本的个数相同，但是样本内容不同。

对于某一个样本，在m个样本里，每次被采集的概率是 $\frac{1}{m}$，不被采集的概率是 $1-\frac{1}{m}$，如果 m 次采样都没有被采集中的概率为$(1-m)^{m}$ 

，当 $m\longrightarrow \infty$ 时，$(1-\frac{1}{m})^{m}\longrightarrow\frac{1}{e}\simeq 0.368$ ，也就是说，在 bagging 每次采样中，训练集中大约有 36.8% 的数据没有被采样集采集。

bagging 对弱学习器没有限制，这和 Adaboost 一样，但是最常用的一般也是决策树和神经网络。

bagging 的结合策略也比较简单，对于分类问题，通常使用投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问

题，通常使用简单平均法，对 $T$ 个弱学习器得到的回归结果进行算术平均得到最终的模型输出。



## 1. bagging算法流程

输入：样本集 $D = \{(x_{1},y_{1}),(x_{2},y_2),\dots(x_{m},y_{m})\}$，弱学习器算法，弱学习器迭代次数 $T$ 

输出：最终的强分类器 $f(x)$

（1）对于 $t=1,2\dots,T$

a）对训练集进行第 $t$ 次采样，共采集 $m$ 次，得到包含 $m$ 个样本的采样集 $D_{t}$

b）用采样集 $D_{t}$ 训练第 $t$ 个弱学习器 $G_{t}(x)$

（2）如果是分类算法预测，则 $T$ 个弱学习器投出最多的票数的类别或者类别之一为最终的类别。如果是回归算法，$T$ 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出



## 2. 随机森林算法（RF）

​	RF思想仍是Bagging算法，只不过多加了些限制		

* RF 使用了 CART 决策树作为弱学习器。
* 在决策树的建立上做了改进，对于**普通的决策树**来说，会在所有 n 个样本特征中去选择一个最优的特征来做决策树的左右子树的划分，RF 则是随机选择一部分特征，特征数假设为 $n_{sub}$ ，然后在随机选择的 $n_{sub}$ 个样本特征中，选择一个最优子树来做决策树的左右子树的划分，进一步增强了模型的泛化能力。$n_{sub}$ 越小，模型越健壮，当然此时对于训练集的拟合程度会变差，也就是说 $n_{sub}$ 越小，模型的方差（测试集的误差）会减小，但是偏差（训练集的误差）会增大，我们需要通过交叉验证法调参获取一个合适的 $n_{sub}$ 的值。

​	**RF算法：**

​	输入：样本集 $D=\{(x_{1},y_{1}),(x_{2},y_{2})\dots(x_{m},y_{m})\}$，弱分类器的迭代次数 $T$

​	输出：最终的强分类器 $f(x)$ 

​	（1）对于 $t=1,2\dots,T$

​	a）对训练集进行第 $t$ 次随机采样，共采集 $m$ 次，得到包含 $m$ 个样本的采样集 $D_{t}$

​	b）用采样集去训练第 $t$ 个决策树模型 $G_{t}(x)$，在训练决策树模型的结点的时候，从样本特征中随机选择一部分样本特征，然后再选择一个最优特征做决策树的左右子树的划分

​	（2）如果是分类预测，则 $T$ 个弱学习器投出最多的票数或最多的票数之一的类别为最终类别，如果是回归算法，则将 $T$ 个弱学习器进行算术平均求得的值作为最终的输出


## 3. 随机森林小结

对于数据量比较大的情况，RF算法很有用

**RF优点：**

（1）训练可以高度并行化，对于大数据时代的大样本训练速度有优势

（2）由于可以随机选择决策树结点划分特征，这样在样本特征维度很高的时候，仍可以高效的训练模型

（3）在训练后，可以给出各个特征对于输出的重要性

（4）由于是随机采样，训练出的模型方差小，泛化能力强

（5）相对于 Boosting 系列的 Adaboost 和 GBDT，RF实现比较简单

（6）对部分特征缺失不敏感

**RF缺点：**

（1）在某些噪音比较大的样本集上，RF 模型容易陷入过拟合

（2）取值划分比较多的特征容易对 RF 的决策产生更大的影响，从而影响拟合模型的效果
